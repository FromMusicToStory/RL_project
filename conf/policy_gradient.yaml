# trainer
gpu: [1]
max_epochs: 200
check_val_every_n_epoch: 2
accumulate_grad_batches: 1
log_every_n_steps: 100
checkpoint_path: "checkpoint/"


model:
  model_name: "klue/roberta-base"
  batch_size: 32
  num_workers: 8
  net:
    policy_net:
      _target_ : network.PolicyNet
      model_name : $(model.model_name)
      num_classes: 10
      distribution: torch.distributions.Categorical
    value_net:
      _target_: network.Classifier
      model_name : $(model.model_name)
      num_classes: $(model.net.policy_net.num_classes)
  gamma: 0.9

  # optimizer
  lr: 5e-5

  # hyperparameter for RL
  sync_rate: 10

  # eps
  eps_start: 1.0
  eps_end: 0.01

  # populate
  initial_eps: 1.0

  gpu: ${gpu}
# seed
seed: 9999

# wandb logger
project: RL
name: PolicyGradient